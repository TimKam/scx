{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Compute desired orderings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "import sys\n",
    "sys.path.append(\"../../src/\")\n",
    "import uncertainpy.gradual as grad\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from scipy.stats import kendalltau, spearmanr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "# get args in a layer\n",
    "def get_layer_nodes(layer_sizes, layer_index=None):\n",
    "    node_id = 0\n",
    "    for i, size in enumerate(layer_sizes):\n",
    "        if i == layer_index:\n",
    "            return [str(n) for n in range(node_id, node_id + size)]\n",
    "        node_id += size\n",
    "\n",
    "    raise ValueError(f\"Invalid layer_index {layer_index}: must be between 0 and {len(layer_sizes) - 1}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "# obtain input_args, hidden_args, output_args\n",
    "def get_layer_args(layer_sizes):\n",
    "    input_size = layer_sizes[0]\n",
    "    output_size = layer_sizes[-1]\n",
    "    total_neurons = sum(layer_sizes)\n",
    "\n",
    "    input_args = [str(i) for i in range(input_size)]\n",
    "\n",
    "    hidden_start = input_size\n",
    "    hidden_end = total_neurons - output_size\n",
    "    hidden_args = [str(i) for i in range(hidden_start, hidden_end)]\n",
    "\n",
    "    output_args = [str(i) for i in range(hidden_end, total_neurons)]\n",
    "\n",
    "    return input_args, hidden_args, output_args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "def compute_loss(bag, preferred_order):\n",
    "    strengths = np.array([bag.arguments[name].strength for name in preferred_order])\n",
    "    i_idx, j_idx = np.triu_indices(len(strengths), k=1)\n",
    "    sigma_diff = strengths[j_idx] - strengths[i_idx]\n",
    "    return np.sum(np.log1p(np.exp(sigma_diff)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "# compute gradient for the loss function\n",
    "def compute_gradient(h, bag, preferred_order):\n",
    "    gradient = {}\n",
    "    original_base_scores = {arg.name: arg.initial_weight for arg in bag.arguments.values()}\n",
    "\n",
    "    # original penalty\n",
    "    grad.algorithms.computeStrengthValues(bag, agg_f, inf_f)\n",
    "    penalty = compute_loss(bag, preferred_order)\n",
    "\n",
    "    for name, original_weight in original_base_scores.items():\n",
    "        # perturb current argument\n",
    "        for arg in bag.arguments.values():\n",
    "            if arg.name == name:\n",
    "                arg.reset_initial_weight(original_weight + h)\n",
    "            else:\n",
    "                arg.reset_initial_weight(original_base_scores[arg.name])\n",
    "\n",
    "        grad.algorithms.computeStrengthValues(bag, agg_f, inf_f)\n",
    "        new_penalty = compute_loss(bag, preferred_order)\n",
    "        gradient[name] = (new_penalty - penalty) / h\n",
    "\n",
    "    # restore all base scores\n",
    "    for arg in bag.arguments.values():\n",
    "        arg.reset_initial_weight(original_base_scores[arg.name])\n",
    "    grad.algorithms.computeStrengthValues(bag, agg_f, inf_f)\n",
    "\n",
    "    return gradient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "# adam optimiser\n",
    "def adam_gradient(name, gradient, m, v, i):\n",
    "\n",
    "    grad = gradient[name]\n",
    "    # Adam optimiser parameters\n",
    "    learning_rate = 0.1  # Initial learning rate\n",
    "    beta1 = 0.85            # First-order moment decay rate\n",
    "    beta2 = 0.98          # Second-order moment decay rate\n",
    "    epsilon = 1e-8         # a small constant\n",
    "\n",
    "    # update first-order moment and second-order moment\n",
    "    m = beta1 * m + (1 - beta1) * grad\n",
    "    v = beta2 * v + (1 - beta2) * (grad ** 2)\n",
    "\n",
    "    # bias correction\n",
    "    m_hat = m / (1 - beta1 ** i)\n",
    "    v_hat = v / (1 - beta2 ** i)\n",
    "\n",
    "    update = learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "\n",
    "    return update, m, v"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "# if the order is exactly the same as the desired order, then valid otherwise not.\n",
    "def is_valid_order(bag, preferred_order):\n",
    "    strengths = np.array([bag.arguments[name].strength for name in preferred_order])\n",
    "    return np.all(strengths[:-1] >= strengths[1:])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "# compute kendall and spearman correlations. if decreasing then 1, increasing 0.\n",
    "def compute_kendall_spearman(predicted_strengths):\n",
    "    if len(set(predicted_strengths)) == 1:\n",
    "        return 1.0, 1.0\n",
    "\n",
    "    ideal_descending = sorted(predicted_strengths, reverse=True)\n",
    "    kendall_corr, _ = kendalltau(ideal_descending, predicted_strengths)\n",
    "    spearman_corr, _ = spearmanr(ideal_descending, predicted_strengths)\n",
    "\n",
    "    return kendall_corr, spearman_corr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "# DF-QuAD gradual semantics\n",
    "agg_f = grad.semantics.modular.ProductAggregation()\n",
    "inf_f = grad.semantics.modular.LinearInfluence(conservativeness=1)\n",
    "\n",
    "layer_sizes = [8,64,16,8,8]\n",
    "N = 100\n",
    "h = 10e-6\n",
    "preferred_order = get_layer_nodes(layer_sizes, len(layer_sizes)-1)\n",
    "input_args, hidden_args, output_args = get_layer_args(layer_sizes)\n",
    "L1 = get_layer_nodes(layer_sizes, len(layer_sizes)-2) # last hidden layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "# #  input mutable\n",
    "# immutable_args = hidden_args + output_args\n",
    "\n",
    "# # hidden mutable\n",
    "# immutable_args = input_args + output_args\n",
    "\n",
    "# # input + hidden mutable\n",
    "# immutable_args = output_args\n",
    "\n",
    "# all mutable\n",
    "immutable_args = []\n",
    "\n",
    "# # # Bespoke:\n",
    "# immutable_args = L1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:28<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_avg:0.94\n",
      "kendall_avg:0.987275641025641\n",
      "spearman_avg:0.9902185479198299\n",
      "runtime_avg:3.28923689365387\n",
      "runtime_median:1.8897062540054321\n",
      "base_score_diff_avg:0.1264976108780872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compute desired orderings for N MLP-like QBAFs\n",
    "valid, kendall, spearman, time_total, base_score_diff = ([0] * N for _ in range(5))\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    start_time = time.time()\n",
    "    filename = f'../../bags/mlp_{i}.bag'\n",
    "    bag = grad.BAG(filename)\n",
    "    m = {}\n",
    "    v = {}\n",
    "    original_base_scores = {arg.name: arg.initial_weight for arg in bag.arguments.values()}\n",
    "\n",
    "    for iteration in range(1, 101):\n",
    "\n",
    "        # compute gradient for all arguments\n",
    "        gradient = compute_gradient(10e-6, bag, preferred_order)\n",
    "        if all(value == 0 for value in gradient.values()): break\n",
    "\n",
    "        # update Adam state and update base scores\n",
    "        for arg in bag.arguments.values():\n",
    "            if arg.name not in immutable_args:\n",
    "                if arg.name not in m:\n",
    "                    m[arg.name] = 0\n",
    "                    v[arg.name] = 0\n",
    "\n",
    "                current_weight = arg.get_initial_weight()\n",
    "                adam_update, m[arg.name], v[arg.name] = adam_gradient(arg.name, gradient, m[arg.name], v[arg.name], iteration)\n",
    "                new_weight = current_weight - adam_update\n",
    "                new_weight = max(0, min(1, new_weight))\n",
    "                arg.reset_initial_weight(new_weight)\n",
    "\n",
    "        # recompute the strength and penalty\n",
    "        grad.algorithms.computeStrengthValues(bag, agg_f, inf_f)\n",
    "        diff = 0\n",
    "        if is_valid_order(bag, preferred_order):\n",
    "            for arg in bag.arguments.values():\n",
    "                diff += abs(arg.initial_weight - original_base_scores[arg.name])\n",
    "            if len(original_base_scores):\n",
    "                base_score_diff[i] = diff/len(original_base_scores)\n",
    "            else:\n",
    "                base_score_diff[i] = 0.0\n",
    "            break\n",
    "\n",
    "    if is_valid_order(bag, preferred_order): valid[i] = 1\n",
    "    predicted_strengths = [bag.arguments[name].strength for name in preferred_order]\n",
    "    kendall[i], spearman[i] = compute_kendall_spearman(predicted_strengths)\n",
    "    time_total[i] = time.time()-start_time\n",
    "\n",
    "print(f\"valid_avg:{sum(valid)/N}\")\n",
    "print(f\"kendall_avg:{sum(kendall)/N}\")\n",
    "print(f\"spearman_avg:{sum(spearman)/N}\")\n",
    "print(f\"runtime_avg:{sum(time_total)/N}\")\n",
    "print(f\"runtime_median:{np.median(time_total)}\")\n",
    "print(f\"base_score_diff_avg:{sum(base_score_diff)/N}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
